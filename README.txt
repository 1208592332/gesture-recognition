利用卷积神经网络实时识别手势动作

一共识别5种手势动作
1. 剪刀动作  2.石头动作 3.布动作  4.OK动作  5.good动作
训练集： 1~4号动作各有1300张照片，5号动作有1450张照片
测试集： 1~5号动作各有200张照片

文件解释：
1.data文件里面存放test数据集，train数据集，实时保存的图像（用于在线检测）。
2.ges_ico文件里面存放界面窗口显示的各种图标。
3.log文件里面存放训练好的CNN网络的模型参数。
4.CallFrame.py是界面窗口的逻辑文件，用来调用界面文件并编写信号与槽函数。
5.Frame.py是界面窗口的界面文件，通过PyQt5的designer工具生成。
6.GetTestImage.py是利用OpenCV获取图片并标记，用来制作测试集。
7.GetTrainImage.py是利用OpenCV获取图片并标记，用来制作训练集。
8.SaveGesture.py是利用OpenCV实时获取图片，并进行预处理，用于在线检测手势。
9.TestGesture.py是将实时获取的图片送入已训练好的CNN中判断其手势动作。
10.TestInTest.py是将测试集送入已训练好的CNN中判断该网络模型的准确率。
11.Train.py是训练CNN模型函数，并将训练好的模型参数保存在本地。
12.Train_inputdata.py是用来读取数据集的图像和标签，并打包成batch形式。
13.Train_model.py是模型结构，这里用的是Alexnet结构。

使用方法：
先用Train.py训练好模型参数，然后运行CallFrame.py调用出界面窗口，
点击窗口的相应按钮就可以在线检测手势动作，其中的执行手势按钮是和下位机通信（如STM32），
通过串口函数将识别结果传给下位机，实现根据手势动作控制的功能。

测试结果：
使用该模型训练到900步的时候在测试集上正确率可以稳定在95%左右。

未来改进：
（1）图像预处理多一些如去除背景  
（2）在线检测图像的时候加一个预选框。





